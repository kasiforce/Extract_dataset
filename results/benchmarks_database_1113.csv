source_paper,benchmark_name,benchmark_name_quote,dataset_url,dataset_url_quote,task_description,task_description_quote,dimension,dimension_quote,evaluation_method,evaluation_method_quote,context_dependency,context_dependency_quote,problem_domain,problem_domain_quote,problem_difficulty,problem_difficulty_quote,language,language_quote,data_size,data_size_quote,source_type,source_type_quote,last_updated,last_updated_quote,build_type,build_type_quote,contamination_status,contamination_status_quote,dataset_license,dataset_license_quote,task_granularity,task_granularity_quote,evaluation_metrics,evaluation_metrics_quote,input_modality,input_modality_quote,output_modality,output_modality_quote,task_io_type,task_io_type_quote,execution_environment,execution_environment_quote,unique_features,unique_features_quote
2511.15757_output/content.md,RGym,"In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware.",,,Linux内核自动程序修复评估，专注于内核空间调试和修复的复杂性,Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on user-space applications and overlook the complexities of kernel-space debugging and repair.,Linux内核程序修复能力评估，包括定位、补丁生成、验证和成本/延迟考虑,"These characteristics make the kernel an ideal stress test for evaluating LLM-based APR, from localization to patch generation, validation, and cost/latency consideration.",通过编译修补后的内核、运行概念验证程序并报告结果来评估补丁质量,"RGym overall compiles patched kernels, runs PoCs, and reports results.",Linux内核级别的复杂依赖关系，包括大规模、深度依赖、普遍并发和硬件底层交互,"with its massive scale, deep dependency, and pervasive concurrency and low-level interactions with hardware.",操作系统内核开发，特别是Linux内核内存安全漏洞修复,"The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions.",高难度内核级bug修复，包含内存损坏等最严重类型的bug,"filtering to KASAN bugs [13], which represent the most severe types of bugs (memory corruption)",C语言（Linux内核开发）,"From 6,088 Syzbot bugs, we retain those with fix commits, reproducers, crash reports, and kernel configs",包含143个已验证的内核bug的数据集,We test on a filtered and verified dataset of 143 bugs.,来自Syzkaller内核模糊测试器和Syzbot自动崩溃报告系统的真实内核bug,"Syzkaller [6], a coverage-guided kernel fuzzer, together with Syzbot [5], an automated online crash reporting system developed by Google, provides a valuable ecosystem that makes kernel-bug collection possible",2025,arXiv:2511.15757v1 [cs.SE] 19 Nov 2025,官方自建，基于真实内核bug构建,We organize a dataset of 143 kernel bugs from Syzbot into an easily consumable format and verified the reproducibility of the bug on the patch parent.,,,,,代码修复，特别是内核内存安全漏洞修复,automated program repair (APR) in the Linux kernel space,补丁通过率（pass rate）、错误补丁率（bad patch rate）、每bug平均成本,Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug.,崩溃报告、调用栈、bug诱导提交、内核配置,"inputs (patch, commit, source, config, compiler, cores, timeout, metadata)",内核补丁代码,"The LLM lists candidate functions, receives their definitions, and returns their patched definitions.",崩溃信息到内核补丁代码,Our APR generates a patch via the Simple Agent or Function Exploration Agent and tests it with RGym.,使用docker捆绑作业依赖和QEMU虚拟机，在本地硬件上运行,RGym runs locally using docker to bundle job dependencies and QEMU for VMs.,轻量级、平台无关的Linux内核APR评估框架，专注于本地商品硬件运行，解决了kGym对GCP的硬依赖问题,"we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. RGym solves the compiler and dependency problem by smartly switching build dependencies using docker images depending on the kernel version or compiler string provided in the kernel configuration."
2511.16005_output/content.md,MultiSWE-bench-CPP,"Evaluated on the MultiSWE-bench-CPP benchmark, InfCode-C++ achieves a resolution rate of 25.58%",https://github.com/Tokfinity/InfCode,"To support the research community and facilitate future work, we release InfCode-C++ and our evaluation benchmark as an open-source project at https://github.com/Tokfinity/InfCode",C++软件问题解决，从自然语言问题描述生成修复补丁,"Given a software repository 𝐶 and a natural-language issue description 𝐷, the objective is to synthesize a patch 𝑝 such that the updated repository 𝐶′ = 𝐶 ⊕ 𝑝 satisfies the behavioral requirements expressed in 𝐷 while preserving the original functionality",代码修复能力、上下文检索准确性、结构分析能力,"Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution",通过回归测试套件验证补丁正确性，使用解决率作为评估指标,"A correct patch must satisfy: 𝑡(𝐶′) = 𝑡(𝐶), ∀𝑡∈𝑇 and ∃𝑡𝐷: 𝑡𝐷(𝐶′) = PASS, where 𝑡𝐷 is a failing test case that captures the erroneous behavior described in 𝐷",仓库级别，涉及多文件C++项目,"repository-level issue resolution... in large, statically typed C++ repositories",软件工程，C++程序修复,"Automated software issue resolution stands as a critical challenge in software engineering... resolving issues in large-scale, high-performance systems written in C++",真实世界工程级难度,"thousands of real-world GitHub issues... a formidable, unsolved challenge",C++,specifically designed for C++ projects... the first C++-aware autonomous system for end-to-end issue resolution,MultiSWE-bench的C++子集,Evaluated on the MultiSWE-bench-CPP benchmark... on the C++ subset of MultiSWE-bench,真实世界的GitHub问题,thousands of real-world GitHub issues,2025,"2025. InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution. 1, 1 (November 2025)",基于现有基准构建的子集,the C++ subset of MultiSWE-bench,,,,,代码修复,issue resolution... synthesize a patch,解决率,achieves a resolution rate of 25.58%,自然语言问题描述,natural-language issue description 𝐷,代码补丁,synthesize a patch 𝑝,文本到代码,from a natural language issue description... synthesize a patch,Docker环境,Repo Codebase Docker Env,专门针对C++语言的复杂性设计，包含语义检索和AST结构化查询,"the first C++-aware autonomous system... combines two complementary retrieval mechanisms—semantic code-intent retrieval and deterministic AST-structured querying—to construct accurate, language-aware context for repair"
2511.17131_output/content.md,UI-CUBE (UiPath Computer Use BEnchmark),"We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs.",https://github.com/UiPath/uipath_enterprise_benchmark,GitHub: https://github.com/UiPath/uipath_enterprise_benchmark,评估计算机使用代理在企业环境中的能力，包括简单的UI交互和复杂的工作流程自动化,Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks),功能正确性、操作可靠性、界面适应性、工作流协调能力,measuring not only functional accuracy but also operational reliability—providing clearer insight into how CUAs can move from experimental demos toward dependable enterprise-grade tools,通过应用程序状态的自动化验证来评估任务成功，包括多分辨率测试和系统界面变化覆盖,"with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state",多步骤工作流程、跨应用程序协调,"complex workflows including copy-paste tasks and enterprise application scenarios, multi-step processes where reliability is as critical as task completion",企业软件自动化、UI交互、工作流程管理,"enterprise application scenarios, enterprise deployment readiness, enterprise workflow automation",两个难度层级：简单UI交互和复杂工作流程,comprising 226 tasks across two difficulty tiers: simple UI interactions (136 tasks) and complex workflows (90 tasks),不特定于编程语言，主要关注UI交互,,226个任务，其中136个简单UI交互任务，90个复杂工作流程任务,comprising 226 tasks across two difficulty tiers: simple UI interactions (136 tasks) and complex workflows (90 tasks comprising 50 copy-paste/business-process tasks and 40 enterprise application tasks),基于企业应用场景的系统构建，包含模拟的企业系统工作流程,"faithful mocks of complex enterprise workflows to test coordination and operational reliability, including testing with workflows from SAP, Workday, and other enterprise systems",2025,arXiv:2511.17131v1 [cs.SE] 21 Nov 2025,官方自建,"we designed UI-CUBE, a new benchmark tailored to enterprise-like conditions, and used it to evaluate our own CUA implementation",,,,,UI交互自动化、工作流程执行,"systematic coverage of atomic UI interactions to map interface-level capabilities, and faithful mocks of complex enterprise workflows to test coordination and operational reliability",任务成功率,"Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%",UI界面、任务指令,"systematic interface variation coverage, multi-resolution testing",UI交互动作、工作流程执行结果,automated validation of task success through the application state,任务指令到UI交互,"measuring task completion effectively, they provide limited assessment of enterprise deployment readiness",企业软件环境、多分辨率显示,All tasks are evaluated across multiple screen resolutions to assess agent consistency under different display conditions,专注于企业级部署准备度评估，揭示能力悬崖现象而非渐进性能下降，提供系统界面分类覆盖,"reveals a sharp capability cliff rather than gradual performance degradation, systematic interface variation coverage, multi-resolution testing"
2511.15755_output/content.md,MyAntFarm.ai,"To test this hypothesis, we present MyAntFarm.ai, a reproducible experimental framework enabling controlled comparison of three conditions",https://github.com/Phildram1/myantfarm-ai,"Source code, Docker configurations, and trial outputs are available at: https://github.com/Phildram1/myantfarm-ai",评估多智能体LLM编排在事件响应中的决策支持质量，通过模拟认证服务回归事件来测试系统生成可执行建议的能力,multi-agent orchestration fundamentally transforms LLM-based incident response quality... achieve 100% actionable recommendation rate,决策质量、行动特异性、解决方案正确性、生产就绪性,"We introduce Decision Quality (DQ), a multi-dimensional metric capturing validity, specificity, and correctness",使用决策质量(DQ)指标，结合有效性、特异性和正确性三个维度进行自动化评分,"DQ measures actionability through three dimensions... Validity, Specificity, Correctness",单事件场景，基于特定的事件遥测数据,All 348 trials used identical context to isolate orchestration effects from scenario variability,运维智能(AIOps)、事件响应、生产环境故障诊断,Modern operational teams face a critical gap between incident detection and actionable comprehension... incident response,生产级事件响应，需要具体的可执行命令,time-critical operational contexts... production deployment,主要使用自然语言进行事件描述和响应生成,The LLM generates a single unstructured text response attempting to address all objectives,348次试验，每个条件116次试验,Through 348 controlled trials... 116 trials per condition,人工构建的模拟事件场景,All 348 trials used identical context... Authentication service regression post-deployment,2025,arXiv:2511.15755v1 [cs.AI] 19 Nov 2025,官方自建的研究框架,"we present MyAntFarm.ai, a reproducible experimental framework",,,,,事件响应决策支持，包括诊断、规划和风险评估,"coordinating specialized LLM agents for diagnosis, planning, and risk assessment",决策质量(DQ)、时间到可用理解(T2U)、有效性、特异性、正确性,"We introduce Decision Quality (DQ), a multi-dimensional metric capturing validity, specificity, and correctness",事件遥测数据和自然语言描述,"Given the following telemetry: Service: auth-service v2.4.0, Error rate: 45%...",结构化的事件简报，包含根本原因、建议行动和风险评估,"A coordinator aggregates the three agent outputs into a structured incident brief containing root cause, recommended actions, and risk assessment",事件数据到决策建议,bridging the gap between detection and actionable comprehension,容器化微服务框架，使用Docker Compose编排,MyAntFarm.ai consists of five containerized microservices orchestrated via Docker Compose,专注于多智能体编排在事件响应中的确定性质量优势，引入决策质量(DQ)这一新的评估指标,"multi-agent systems exhibit zero quality variance across all trials, making them production-ready... We introduce Decision Quality (DQ), a multi-dimensional metric capturing validity, specificity, and correctness"
2511.16708_output/content.md,CodeX-Verify,"We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs.",,,多智能体代码验证系统，使用四个专门化的智能体来检测不同类型的代码错误,"We built CodeX-Verify, a system that runs four specialized agents in parallel: Correctness (logic errors, edge cases, exception handling), Security (OWASP Top 10, CWE patterns, secrets), Performance (algorithmic complexity, resource leaks), and Style (maintainability, documentation). Each agent looks for different bug types.",代码正确性、安全性、性能和风格四个维度的错误检测,"Correctness (logic errors, edge cases, exception handling), Security (OWASP Top 10, CWE patterns, secrets), Performance (algorithmic complexity, resource leaks), and Style (maintainability, documentation)",在99个带有验证标签的代码样本上进行测试，测量真阳性率和准确率,"Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution.",,,软件工程、代码验证、漏洞检测,Multi-Agent Code Verification with Compound Vulnerability Detection,,,,,99个代码样本，覆盖16个错误类别,Dataset of 99 code samples with verified labels covering 16 bug categories,来自真实SWE-bench失败的代码样本,covering 16 bug categories from real SWE-bench failures,2025,October 2025,官方自建,We built CodeX-Verify,,,开源发布,released open-source,代码验证和错误检测,detect different types of bugs,真阳性率、准确率、假阳性率,"catches 76.1% of bugs, achieving 76.1% TPR with 68.7% accuracy (±9.1% CI)",代码,code samples,错误检测结果,detect different types of bugs,代码到错误检测结果,"analyzes code c ∈C through domain-specific function ϕi : C →Oi, producing observation Ai = ϕi(c) and decision Di ∈{0, 1}",无需执行代码的静态分析,running faster and without executing code,多智能体协同验证、复合漏洞风险建模、数学理论证明、测试15种智能体组合,"We tested all 15 combinations of agents: single agents (4 configs), pairs (6 configs), triples (4 configs), and the full system. We formalize how multiple vulnerabilities in the same code create exponentially more risk. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent."
2511.21509_output/content.md,SV-LIB 1.0,SV-LIB 1.0: A Standard Exchange Format for Software-Verification Tasks,https://gitlab.com/sosy-lab/benchmarking/sv-lib,https://gitlab.com/sosy-lab/benchmarking/sv-lib,软件验证任务的交换格式和中间语言，包括程序、规范和验证见证,"we propose SV-LIB, an exchange format and intermediate language for software-verification tasks, including programs, specifications, and verification witnesses.",软件验证、程序分析、交换格式、验证见证,"Additional Key Words and Phrases: Software verification, Program analysis, Exchange format, Witness, Certifying Algorithm, Intermediate language, SV-LIB, SMT-LIB",,,,,软件验证、程序分析,"Additional Key Words and Phrases: Software verification, Program analysis, Exchange format, Witness, Certifying Algorithm, Intermediate language, SV-LIB, SMT-LIB",,,基于命令式编程语言概念，使用SMT-LIB表示表达式和类型,SV-LIB is based on well-known concepts from imperative programming languages and uses SMT-LIB to represent expressions and sorts used in the program.,,,,,2025-11-26,Version 1.0 SV-LIB 2025-11-26,官方自建,"we propose SV-LIB, an exchange format and intermediate language for software-verification tasks",,,,,软件验证任务交换格式,"SV-LIB, an exchange format and intermediate language for software-verification tasks",,,程序、规范和验证见证,"including programs, specifications, and verification witnesses",验证结果和见证,SV-LIB defines a witness format for both correct and incorrect SV-LIB programs,软件验证任务到验证结果,exchange format and intermediate language for software-verification tasks,基于SMT求解器的验证工具基础设施,"This makes it easy to parse and to build into existing infrastructure, since many verification tools are based on SMT solvers already.",定义了正确和错误程序的见证格式，支持独立见证验证器，可重用验证器作为见证验证器,"Furthermore, SV-LIB defines a witness format for both correct and incorrect SV-LIB programs, together with means for specifying witness-validation tasks. This makes it possible both to implement independent witness validators and to reuse some verifiers also as validators for witnesses."
2511.15817_output/content.md,CodeSmellEval,"The CodeSmellEval benchmark [37] proposed the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating specific types of smell.",,,评估大型语言模型生成代码的结构质量，特别是其产生代码异味（即影响可读性、可维护性或设计完整性的模式）的倾向性。,"This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality.",代码结构质量，具体为代码异味的倾向性。,"We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality.",使用倾向性异味分数（PSC），这是一个基于模型在自回归生成过程中预测的下一个令牌概率的概率度量。,The Propensity Smelly Score (PSC) is a probabilistic metric that estimates the likelihood that a LLM generates a specific type of code smell [37]. It relies on the next-token probabilities predicted by the model during autoregressive generation.,,,软件工程，代码质量评估。,"Code smells offer a foundation for evaluating these broader quality concerns. They capture recurring design and implementation issues that affect readability, complexity, and long-term maintainability [8, 23, 36].",,,Python（从示例代码片段推断）,"Figure 1: Propensity Smelly Score (SCM) Computation. The python snippet at the bottom contains two code smells: C0103 (i.e., invalid-name) and C0415 (i.e., import-outside-toplevel).",,,,,2026,"In 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE ’26), April 12–18, 2026, Rio de Janeiro, Brazil.",官方自建（基于先前工作）,The CodeSmellEval benchmark [37] proposed the Propensity Smelly Score (PSC)...,,,知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议,This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.,代码生成,"LLMs have rapidly moved from experimental tools to everyday assistants in software engineering (SE) [38]. Developers rely on them for many tasks such as code completion [5, 16, 41], summarization [1], program repair [11], clone detection [40] and test generation [39].",倾向性异味分数（PSC）,"We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types...",,,代码,"This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code.",,,,,该基准专注于代码异味（结构质量问题）的倾向性评估，而非传统的功能正确性。它引入了一个概率性度量（PSC），用于估计模型生成特定类型异味的可能性，并可作为因果分析的工具来理解生成过程中的影响因素。,"Instead of treating PSC as a standalone benchmark metric, we use it as an instrument for reasoning about the factors that influence smell propensity in LLM-generated code. Our study begins by assessing the robustness and explanatory value of PSC, establishing that it provides a stable foundation for causal analysis."
2512.03421_output/content.md,BugT,"This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns.",https://github.com/Xucranger/PLofLBFL,"To facilitate future study, we share our source code and experimental data in a GitHub repository 1. 1https://github.com/Xucranger/PLofLBFL",评估大型语言模型在初学者程序故障定位任务中的性能。,"This study evaluates the fault localization performance of six closed-source LLMs (e.g., OpenAI o3, GPT-3.5-Turbo, etc.) and seven open-source LLMs (e.g., DeepSeekR1, Llama3, etc.) across Codeflaws, Condefects, and BugT datasets.",故障定位的准确性、效率、可用性，以及对问题难度的鲁棒性。,"To investigate these issues, we aim to empirically assess the performance of different LLMs across various datasets, evaluating their accuracy, efficiency, and usability in fault localization for novice programs.",在多个数据集上评估LLMs的故障定位性能，并与传统方法（如SBFL、MBFL）进行比较。,"This study evaluates the fault localization performance of six closed-source LLMs (e.g., OpenAI o3, GPT-3.5-Turbo, etc.) and seven open-source LLMs (e.g., DeepSeekR1, Llama3, etc.) across Codeflaws, Condefects, and BugT datasets. All closed-source LLMs outperform traditional SBFL and MBFL methods...",针对包含错误的初学者程序代码片段。,"Novice Program [18] refers to code written by novice programmers, usually in the early stages of learning programming. These programs usually contain multiple errors...",编程教育，特别是针对初学者的故障定位和调试。,Novice programming assistance [19] is a crucial educational approach aimed at helping students develop their fundamental coding skills and enhance problem-solving abilities.,包含不同难度级别的问题，从简单到复杂。,"LLM accuracy decreases as problem difficulty increases in Codeflaws and Condefects, but top models maintain high accuracy even at peak difficulty in BugT, suggesting its lower complexity.",,,,,自建的包含真实编程错误的数据集。,"We introduce a new self-created dataset with real programming faults, aiming to mitigate data leakage concerns and establish a more reliable evaluation benchmark for assessing LLMs’ capabilities.",2025,"Preprint submitted to Journal of LATEX Templates December 4, 2025",官方自建,We introduce a new self-created dataset with real programming faults...,专门设计以减轻数据泄露问题。,...with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns.,,,故障定位,This study evaluates the fault localization performance...,,,包含错误的代码,"Novice Program [18] refers to code written by novice programmers, usually in the early stages of learning programming. These programs usually contain multiple errors...",故障位置和解释,LLM generated fault explanations demonstrate significant value for novice programmer assistance...,代码到文本（故障位置/解释）,LLM generated fault explanations demonstrate significant value for novice programmer assistance...,,,专门为初学者编程教育设计，旨在减轻数据泄露问题，并包含真实编程错误。,...with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. ...We introduce a new self-created dataset with real programming faults...
2512.05073_output/content.md,Comprehensive Verilog Design Problems (CVDP),"The Comprehensive Verilog Design Problems (CVDP) benchmark [25], developed by NVIDIA, provides rigorous evaluation with 336 problems across arithmetic operations, control logic, memory systems, and miscellaneous designs.",,,从自然语言规范生成经过验证的寄存器传输级（RTL）硬件设计实现。,transform design intent from the CVDP dataset into verified register transfer level (RTL) implementations.,硬件设计自动化能力，包括代码生成和代码理解。,"We evaluate SLM models (1.7B–20B) across code generation and comprehension, establishing baseline performance.",使用基于CocoTB的测试套件评估功能正确性。,"Each includes natural language specification, module interface, functional requirements, and CocoTB-based test suites.",单模块设计问题，包含接口规范和功能要求。,"Each includes natural language specification, module interface, functional requirements, and CocoTB-based test suites.",硬件设计，具体为Verilog硬件描述语言编程。,"The Comprehensive Verilog Design Problems (CVDP) benchmark [25], developed by NVIDIA, provides rigorous evaluation with 336 problems across arithmetic operations, control logic, memory systems, and miscellaneous designs.",代表现实世界复杂性的生产级IP块。,"Derived from production IP blocks, it represents realistic complexity.",Verilog硬件描述语言。,"The Comprehensive Verilog Design Problems (CVDP) benchmark [25], developed by NVIDIA, provides rigorous evaluation with 336 problems across arithmetic operations, control logic, memory systems, and miscellaneous designs.",包含336个问题。,"The Comprehensive Verilog Design Problems (CVDP) benchmark [25], developed by NVIDIA, provides rigorous evaluation with 336 problems across arithmetic operations, control logic, memory systems, and miscellaneous designs.",源自NVIDIA的生产IP块。,"Derived from production IP blocks, it represents realistic complexity.",,,官方自建（由NVIDIA开发）。,"The Comprehensive Verilog Design Problems (CVDP) benchmark [25], developed by NVIDIA, provides rigorous evaluation with 336 problems across arithmetic operations, control logic, memory systems, and miscellaneous designs.",,,,,代码生成（从规范生成RTL代码）。,transform design intent from the CVDP dataset into verified register transfer level (RTL) implementations.,通过率（pass rate）。,"State-of-the-art achieves only 26.5% pass rate (GPT-4o-mini, single-shot), highlighting substantial improvement opportunity.",自然语言规范、模块接口和功能要求。,"Each includes natural language specification, module interface, functional requirements, and CocoTB-based test suites.",Verilog RTL代码。,transform design intent from the CVDP dataset into verified register transfer level (RTL) implementations.,文本到代码。,transform design intent from the CVDP dataset into verified register transfer level (RTL) implementations.,基于CocoTB的测试套件。,"Each includes natural language specification, module interface, functional requirements, and CocoTB-based test suites.",专注于硬件设计（Verilog）的基准，问题源自现实世界的生产IP块，涵盖算术运算、控制逻辑、内存系统等多种设计类别。,"The Comprehensive Verilog Design Problems (CVDP) benchmark [25], developed by NVIDIA, provides rigorous evaluation with 336 problems across arithmetic operations, control logic, memory systems, and miscellaneous designs. Derived from production IP blocks, it represents realistic complexity."
2511.16787_output/content.md,BLP-2025 Shared Task on Code Generation from Bangla Instructions,This paper presents the winning system for the BLP-2025 Shared Task on Code Generation from Bangla Instructions,,,根据给定的孟加拉语指令生成Python代码。指令包含孟加拉语描述、函数名和参数名。,"The goal of the shared task is to generate Python code from a given Bangla instruction. The instruction itself contains the given Bangla instruction, function name, and argument names.",从非英语（孟加拉语）自然语言指令生成代码的功能正确性,"This imbalance narrows access to program-synthesis tools for non-English speakers and limits our understanding of how linguistic factors – such as morphology, script variation, and code-mixing – impact the path from instructions to executable programs.",使用pytest风格的单元测试评估生成代码的功能正确性，采用Pass@1指标,"The candidate program is then executed against the provided unit tests (pytest-style, assert-based). ... For this task, the evaluation metric is Pass@1 (Chen et al., 2021).",单函数生成，依赖指令和单元测试,A candidate program must define the function precisely as provided by the function name since pytest is designed with the same function names.,通用编程问题,,,,Python,"This paper presents the winning system for the BLP-2025 Shared Task on Code Generation from Bangla Instructions, which consists of a multi-agent pipeline. First, a code-generation agent produces an initial solution from the input instruction.",开发集400个孟加拉语指令，测试集500个孟加拉语指令,"Development dataset Our development set consists of 400 Bangla instructions paired with function names, each accompanied by three unit tests. ... Test dataset The test set contains 500 Bangla instructions with function names, each accompanied by a single unit test",由任务组织者提供,"The organizers provide this dataset (Raihan et al., 2025a).",2025,BLP-2025 Shared Task on Code Generation from Bangla Instructions,官方自建（共享任务组织者）,"The organizers provide this dataset (Raihan et al., 2025a).",,,,,代码生成,The goal of the shared task is to generate Python code from a given Bangla instruction.,Pass@1,"For this task, the evaluation metric is Pass@1 (Chen et al., 2021).",自然语言（孟加拉语）,The goal of the shared task is to generate Python code from a given Bangla instruction.,代码（Python）,The goal of the shared task is to generate Python code from a given Bangla instruction.,文本到代码,The goal of the shared task is to generate Python code from a given Bangla instruction.,pytest测试环境,"The candidate program is then executed against the provided unit tests (pytest-style, assert-based).",专注于孟加拉语到Python代码生成，填补非英语代码生成评测的空白,"However, most benchmarks and systems remain vastly English-centric (Jiang et al., 2024). ... Bangla – spoken by over 270 million people worldwide – is an example of an inadequately supported language in this area."
2512.05908_output/content.md,DNext,"Our evaluation is performed on DNext [7], a proprietary, industrial-scale microservice system for the telecommunications sector.",,,在多仓库微服务架构中，根据自然语言错误报告定位错误所在的代码文件。,Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code... We propose reframing this as a natural language reasoning task... performing NL-to-NL search instead of cross-modal retrieval.,错误定位的准确性和效率，特别是在多仓库环境下的搜索空间路由和分层定位能力。,"Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories.",使用Pass@k和Recall@k指标进行评估，其中k=10用于文件定位，k=3用于仓库路由。同时使用平均倒数排名（MRR）。,"We evaluate performance using standard metrics: Pass@k and Recall@k. Pass@k measures the proportion of bug reports where at least one correct file is found in the top-𝑘 results. Recall@k measures the fraction of all correct files for a given bug that are successfully retrieved within the top-𝑘 results. Given that the maximum number of modified files for any bug in our dataset is 10 (average 7.2), we set 𝑘= 10 as a fair and comprehensive threshold... For the preliminary search space routing phase, we use a tighter 𝑘= 3.",多仓库、多文件项目，涉及文件、目录和仓库三个层次。,"Our approach builds context-aware summaries at file, directory, and repository levels... This structured repository →directory →file search path provides an inherently transparent and auditable reasoning process.",软件工程，特别是电信领域的微服务架构系统。,"Our evaluation is performed on DNext [7], a proprietary, industrial-scale microservice system for the telecommunications sector.",工业级，包含真实、嘈杂的错误报告，规模大且复杂。,"Its scale (see Table 1) and use of real-world, often noisy, bug reports provide a challenging benchmark that standard academic datasets cannot replicate.",Java,Programming Language: Java,包含46个仓库，7077个代码文件，约110万行物理代码，87个错误工单，平均每个工单涉及7.2个错误文件。,"Number of Repositories: 46, Total Number of Code Files: 7,077, Total Physical Lines of Code: ∼1.1M, Number of Bug Tickets: 87, Average Buggy Files per Ticket: 7.2",专有的工业级微服务系统，错误工单的基准事实是解决该问题的拉取请求中修改的文件集。,"Our evaluation is performed on DNext [7], a proprietary, industrial-scale microservice system... The ground truth for each bug ticket is the set of files modified in the pull request that resolved the issue.",2026,"ICSE 2026, Rio de Janeiro, Brazil",官方自建（专有工业系统）,"a proprietary, industrial-scale microservice system",,,,,代码检索/定位,"Bug Localization, Code Retrieval","Pass@10, Recall@10, MRR (用于文件定位)；Pass@3, Recall@3, MRR (用于仓库路由)","We evaluate performance using standard metrics: Pass@k and Recall@k... we set 𝑘= 10... For the preliminary search space routing phase, we use a tighter 𝑘= 3.",自然语言（错误报告）,natural language bug reports,代码文件列表（排名）,produces the final ranked list of files most likely to be the source of the bug.,文本到代码（检索）,reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval.,,,专为多仓库微服务架构中的错误定位设计，使用分层自然语言摘要（文件、目录、仓库级）将问题重构为NL-to-NL推理任务，并提供可解释的仓库→目录→文件搜索路径。,"Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories... This structured repository →directory →file search path provides an inherently transparent and auditable reasoning process."
