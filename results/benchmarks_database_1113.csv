source_paper,benchmark_name,benchmark_name_quote,dataset_url,dataset_url_quote,task_description,task_description_quote,dimension,dimension_quote,evaluation_method,evaluation_method_quote,context_dependency,context_dependency_quote,problem_domain,problem_domain_quote,problem_difficulty,problem_difficulty_quote,language,language_quote,data_size,data_size_quote,source_type,source_type_quote,last_updated,last_updated_quote,build_type,build_type_quote,contamination_status,contamination_status_quote,dataset_license,dataset_license_quote,task_granularity,task_granularity_quote,evaluation_metrics,evaluation_metrics_quote,input_modality,input_modality_quote,output_modality,output_modality_quote,execution_environment,execution_environment_quote,unique_features,unique_features_quote
content.md,"HumanEval-x, CodefuseEval","Extensive experiments are conducted using real-world usage scenarios, the industry-standard benchmark HumanEval-x, and the specially designed CodefuseEval for Chinese prompts.",https://github.com/codefuse-ai/codefuse-evaluation,"Moreover, we developed and open-sourced a more comprehensive benchmark, named CodefuseEval3, to support for a broader range of programming scenarios involving Chinese inputs.",代码生成、代码翻译、代码注释、测试用例生成等多语言代码相关任务,"In practical scenarios, such as code generation, code translation, code comments, and testcase generation, CodeFuse performs better than other models when confronted with Chinese prompts.",多语言代码理解能力、功能正确性,"However, the effectiveness of existing models in understanding non-English inputs for multi-lingual code-related tasks is still far from well studied.",pass@1指标、人工反馈评估,"The results demonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%, positioning it as one of the top multi-lingual code LLMs with similar parameter sizes.",,,软件工程、编程开发,Code Large Language Models (Code LLMs) have gained significant attention in the industry due to their wide applications in the full lifecycle of software engineering.,,,支持40多种编程语言，包括Java、Python、C++、JavaScript等,It is specifically designed for code-related tasks with both English and Chinese prompts and supports over 40 programming languages.,HumanEval基准测试，包含164个Python编程问题,The results demonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%,行业标准基准测试和专门设计的中文提示评估集,"Extensive experiments are conducted using real-world usage scenarios, the industry-standard benchmark HumanEval-x, and the specially designed CodefuseEval for Chinese prompts.",2024,"ICSE-SEIP '24, April 14–20, 2024, Lisbon, Portugal",官方自建,"Moreover, we developed and open-sourced a more comprehensive benchmark, named CodefuseEval3, to support for a broader range of programming scenarios involving Chinese inputs.",,,,,代码生成、代码翻译、代码注释、测试用例生成,"In practical scenarios, such as code generation, code translation, code comments, and testcase generation, CodeFuse performs better than other models when confronted with Chinese prompts.",pass@1,The results demonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%,自然语言（英文和中文提示）,It is specifically designed for code-related tasks with both English and Chinese prompts,代码,"In practical scenarios, such as code generation, code translation, code comments, and testcase generation",,,专门针对中文提示优化的多语言代码评估基准，支持40多种编程语言,It is specifically designed for code-related tasks with both English and Chinese prompts and supports over 40 programming languages.
