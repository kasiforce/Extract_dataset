topic,paper_id,title,authors,first_author,primary_category,publish_time,update_time,comments,abstract,pdf_path,paper_url,download_time,query
LLM Testing,2501.11354,Towards Advancing Code Generation with Large Language Models: A Research Roadmap,"Haolin Jin, Huaming Chen, Qinghua Lu, Liming Zhu",Haolin Jin,cs.SE,2025-01-20,2025-01-20,,"Recently, we have witnessed the rapid development of large language models, which have demonstrated excellent capabilities in the downstream task of code generation. However, despite their potential, LLM-based code generation still faces numerous technical and evaluation challenges, particularly when embedded in real-world development. In this paper, we present our vision for current research directions, and provide an in-depth analysis of existing studies on this task. We propose a six-layer vision framework that categorizes code generation process into distinct phases, namely Input Phase, Orchestration Phase, Development Phase, and Validation Phase. Additionally, we outline our vision workflow, which reflects on the currently prevalent frameworks. We systematically analyse the challenges faced by large language models, including those LLM-based agent frameworks, in code generation tasks. With these, we offer various perspectives and actionable recommendations in this area. Our aim is to provide guidelines for improving the reliability, robustness and usability of LLM-based code generation systems. Ultimately, this work seeks to address persistent challenges and to provide practical suggestions for a more pragmatic LLM-based solution for future code generation endeavors.",./papers_benchmark\2501.11354.pdf,https://arxiv.org/abs/2501.11354,2025-10-25 22:50:29,"(llm OR ""large language model"") AND (""code generation"")"
LLM Testing,2311.00272,ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation,"Zejun Wang, Jia Li, Ge Li, Zhi Jin",Zejun Wang,cs.SE,2023-11-01,2023-11-01,,"Large language models have shown good performances in generating code to meet human requirements. However, human requirements expressed in natural languages can be vague, incomplete, and ambiguous, leading large language models to misunderstand human requirements and make mistakes. Worse, it is difficult for a human user to refine the requirement. To help human users refine their requirements and improve large language models' code generation performances, we propose ChatCoder: a method to refine the requirements via chatting with large language models. We design a chat scheme in which the large language models will guide the human users to refine their expression of requirements to be more precise, unambiguous, and complete than before. Experiments show that ChatCoder has improved existing large language models' performance by a large margin. Besides, ChatCoder has the advantage over refine-based methods and LLMs fine-tuned via human response.",./papers_benchmark\2311.00272.pdf,https://arxiv.org/abs/2311.00272,2025-10-25 22:50:47,"(llm OR ""large language model"") AND (""code generation"")"
