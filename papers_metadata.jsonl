// 可手动添加论文，确保论文title不为空
{"paper_id": "2501.11354", "title": "Towards Advancing Code Generation with Large Language Models: A Research Roadmap", "abstract": "Recently, we have witnessed the rapid development of large language models, which have demonstrated excellent capabilities in the downstream task of code generation. However, despite their potential, LLM-based code generation still faces numerous technical and evaluation challenges, particularly when embedded in real-world development. In this paper, we present our vision for current research directions, and provide an in-depth analysis of existing studies on this task. We propose a six-layer vision framework that categorizes code generation process into distinct phases, namely Input Phase, Orchestration Phase, Development Phase, and Validation Phase. Additionally, we outline our vision workflow, which reflects on the currently prevalent frameworks. We systematically analyse the challenges faced by large language models, including those LLM-based agent frameworks, in code generation tasks. With these, we offer various perspectives and actionable recommendations in this area. Our aim is to provide guidelines for improving the reliability, robustness and usability of LLM-based code generation systems. Ultimately, this work seeks to address persistent challenges and to provide practical suggestions for a more pragmatic LLM-based solution for future code generation endeavors.", "paper_url": "https://arxiv.org/abs/2501.11354", "authors": "Haolin Jin, Huaming Chen, Qinghua Lu, Liming Zhu", "first_author": "Haolin Jin", "primary_category": "cs.SE", "topic": "LLM Coding", "pdf_path": "./papers\\2501.11354.pdf", "publish_time": "2025-01-20", "update_time": "2025-01-20", "comments": "", "download_time": "2025-10-28 11:46:05", "query": "(llm OR \"large language model\") AND (\"code generation\")"}
{"paper_id": "2311.00272", "title": "ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation", "abstract": "Large language models have shown good performances in generating code to meet human requirements. However, human requirements expressed in natural languages can be vague, incomplete, and ambiguous, leading large language models to misunderstand human requirements and make mistakes. Worse, it is difficult for a human user to refine the requirement. To help human users refine their requirements and improve large language models' code generation performances, we propose ChatCoder: a method to refine the requirements via chatting with large language models. We design a chat scheme in which the large language models will guide the human users to refine their expression of requirements to be more precise, unambiguous, and complete than before. Experiments show that ChatCoder has improved existing large language models' performance by a large margin. Besides, ChatCoder has the advantage over refine-based methods and LLMs fine-tuned via human response.", "paper_url": "https://arxiv.org/abs/2311.00272", "authors": "Zejun Wang, Jia Li, Ge Li, Zhi Jin", "first_author": "Zejun Wang", "primary_category": "cs.SE", "topic": "LLM Coding", "pdf_path": "./papers\\2311.00272.pdf", "publish_time": "2023-11-01", "update_time": "2023-11-01", "comments": "", "download_time": "2025-10-28 11:46:18", "query": "(llm OR \"large language model\") AND (\"code generation\")"}
{"paper_id": "2007.11671", "title": "DeepClone: Modeling Clones to Generate Code Predictions", "abstract": "Programmers often reuse code from source code repositories to reduce the development effort. Code clones are candidates for reuse in exploratory or rapid development, as they represent often repeated functionality in software systems. To facilitate code clone reuse, we propose DeepClone, a novel approach utilizing a deep learning algorithm for modeling code clones to predict the next set of tokens (possibly a complete clone method body) based on the code written so far. The predicted tokens require minimal customization to fit the context. DeepClone applies natural language processing techniques to learn from a large code corpus, and generates code tokens using the model learned. We have quantitatively evaluated our solution to assess (1) our model's quality and its accuracy in token prediction, and (2) its performance and effectiveness in clone method prediction. We also discuss various application scenarios for our approach.", "paper_url": "https://arxiv.org/abs/2007.11671", "authors": "Muhammad Hammad, Önder Babur, Hamid Abdul Basit, Mark van den Brand", "first_author": "Muhammad Hammad", "primary_category": "cs.SE", "topic": "Code Completion", "benchmark": false, "conference": null, "pdf_path": "./papers\\2007.11671.pdf", "publish_time": "2020-07-22", "update_time": "2020-12-08", "download_time": "2025-11-13 21:44:05"}
