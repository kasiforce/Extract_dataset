{"paper_id": "2508.21107", "title": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "abstract": "Unit testing is a core practice in programming, enabling systematic evaluation of programs produced by human developers or large language models (LLMs). Given the challenges in writing comprehensive unit tests, LLMs have been employed to automate test generation, yet methods for training LLMs to produce high-quality tests remain underexplored. In this work, we propose UTRL, a novel reinforcement learning framework that trains an LLM to generate high-quality unit tests given a programming instruction. Our key idea is to iteratively train two LLMs, the unit test generator and the code generator, in an adversarial manner via reinforcement learning. The unit test generator is trained to maximize a discrimination reward, which reflects its ability to produce tests that expose faults in the code generator's solutions, and the code generator is trained to maximize a code reward, which reflects its ability to produce solutions that pass the unit tests generated by the test generator. In our experiments, we demonstrate that unit tests generated by Qwen3-4B trained via UTRL show higher quality compared to unit tests generated by the same model trained via supervised fine-tuning on human-written ground-truth unit tests, yielding code evaluations that more closely align with those induced by the ground-truth tests. Moreover, Qwen3-4B trained with UTRL outperforms frontier models such as GPT-4.1 in generating high-quality unit tests, highlighting the effectiveness of UTRL in training LLMs for this task.", "paper_url": "https://arxiv.org/abs/2508.21107", "authors": "Dongjun Lee, Changho Hwang, Kimin Lee", "first_author": "Dongjun Lee", "primary_category": "cs.SE", "topic": "LLM Coding", "pdf_path": "./papers/2508.21107.pdf", "publish_time": "2025-08-28", "update_time": "2025-09-30", "comments": "Code is available at: https://github.com/dgjun32/UTRL", "download_time": "2025-11-05 12:50:15", "query": "(llm OR \"large language model\") AND (\"code generation\" OR \"test generation\")"}
{"paper_id": "2311.00272", "title": "ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation", "abstract": "Large language models have shown good performances in generating code to meet human requirements. However, human requirements expressed in natural languages can be vague, incomplete, and ambiguous, leading large language models to misunderstand human requirements and make mistakes. Worse, it is difficult for a human user to refine the requirement. To help human users refine their requirements and improve large language models' code generation performances, we propose ChatCoder: a method to refine the requirements via chatting with large language models. We design a chat scheme in which the large language models will guide the human users to refine their expression of requirements to be more precise, unambiguous, and complete than before. Experiments show that ChatCoder has improved existing large language models' performance by a large margin. Besides, ChatCoder has the advantage over refine-based methods and LLMs fine-tuned via human response.", "paper_url": "https://arxiv.org/abs/2311.00272", "authors": "Zejun Wang, Jia Li, Ge Li, Zhi Jin", "first_author": "Zejun Wang", "primary_category": "cs.SE", "topic": "LLM Coding", "pdf_path": "./papers/2311.00272.pdf", "publish_time": "2023-11-01", "update_time": "2023-11-01", "comments": "", "download_time": "2025-11-05 12:50:15", "query": "(llm OR \"large language model\") AND (\"code generation\" OR \"test generation\")"}
