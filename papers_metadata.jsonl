{"id": "2511.12385", "title": "GenSIaC: Toward Security-Aware Infrastructure-as-Code Generation with Large Language Models", "abstract": "In recent years, Infrastructure as Code (IaC) has emerged as a critical approach for managing and provisioning IT infrastructure through code and automation. IaC enables organizations to create scalable and consistent environments, effectively managing servers and development settings. However, the growing complexity of cloud infrastructures has led to an increased risk of misconfigurations and security vulnerabilities in IaC scripts. To address this problem, this paper investigates the potential of Large Language Models (LLMs) in generating security-aware IaC code, avoiding misconfigurations introduced by developers and administrators.   While LLMs have made significant progress in natural language processing and code generation, their ability to generate secure IaC scripts remains unclear. This paper addresses two major problems: 1) the lack of understanding of security weaknesses in IaC scripts generated by LLMs, and 2) the absence of techniques for enhancing security in generating IaC code with LLMs.   To assess the extent to which LLMs contain security knowledge, we first conduct a comprehensive evaluation of base LLMs in recognizing major IaC security weaknesses during the generation and inspection of IaC code. Then, we propose GenSIaC, an instruction fine-tuning dataset designed to improve LLMs' ability to recognize potential security weaknesses. Leveraging GenSIaC, we fine-tune LLMs and instruct models to generate security-aware IaC code. Our evaluation demonstrates that our models achieve substantially improved performance in recognizing and preventing IaC security misconfigurations, e.g., boosting the F1-score from 0.303 to 0.858. Additionally, we perform ablation studies and explore GenSIaC's generalizability to other LLMs and its cross-language capabilities.", "arxiv_url": "https://arxiv.org/abs/2511.12385", "authors": ["Yikun Li", "Matteo Grella", "Daniel Nahmias", "Gal Engelberg", "Dan Klein", "Giancarlo Guizzardi", "Thijs van Ede", "Andrea Continella"], "first_author": "Yikun Li", "primary_category": "cs.CR", "tag": ["Code Instruction-Tuning"], "benchmark": true, "conference": null, "pdf_url": "https://arxiv.org/pdf/2511.12385v1", "published": "2025-11-15", "update_time": "2025-11-15", "download_time": "2025-11-18 10:37:43"}
{"id": "2511.12294", "title": "ProofWright: Towards Agentic Formal Verification of CUDA", "abstract": "Large Language Models (LLMs) are increasingly used to automatically generate optimized CUDA kernels, substantially improving developer productivity. However, despite rapid generation, these kernels often contain subtle correctness bugs and lack formal safety guarantees. Runtime testing is inherently unreliable - limited input coverage and reward hacking can mask incorrect behavior - while manual formal verification is reliable but cannot scale to match LLM output rates, creating a critical validation bottleneck.   We present ProofWright, an agentic verification framework that bridges this gap by integrating automated formal verification with LLM-based code generation. ProofWright provides end-to-end guarantees of memory safety, thread safety, and semantic correctness for LLM-generated CUDA kernels. On KernelBench L1, ProofWright verifies safety properties for 74% of generated kernels, uncovers subtle correctness errors missed by conventional testing, and establishes semantic equivalence for a class of element-wise kernels. With a modest overhead of 3 minutes per kernel, ProofWright demonstrates that scalable, automated formal verification of LLM-generated GPU code is feasible - offering a path toward trustworthy high-performance code generation without sacrificing developer productivity.", "arxiv_url": "https://arxiv.org/abs/2511.12294", "authors": ["Bodhisatwa Chatterjee", "Drew Zagieboylo", "Sana Damani", "Siva Hari", "Christos Kozyrakis"], "first_author": "Bodhisatwa Chatterjee", "primary_category": "cs.SE", "tag": ["Code Formal Verification"], "benchmark": false, "conference": null, "pdf_url": "https://arxiv.org/pdf/2511.12294v1", "published": "2025-11-15", "update_time": "2025-11-15", "download_time": "2025-11-18 10:37:55"}
